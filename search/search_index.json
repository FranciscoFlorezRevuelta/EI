{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Summary","text":""},{"location":"#course-syllabus-and-rules","title":"Course Syllabus and Rules","text":"<p>These are the teaching materials for the course Entornos Inteligentes (Intelligent Environments), coordinated by Francisco Fl\u00f3rez (LinkedIn) and also taught by Jos\u00e9 Garc\u00eda (LinkedIn), and Pau Climent (LinkedIn).</p> <p>For information regarding the course assessment, please refer to the Moodle contents at UACloud and the course official info page. </p> <p>Regarding the methodology:</p> <ul> <li>The theory contents should be revised by the student before attending the practical sessions. A test will be answered to ensure that these contents are read and understood by the student. The tests represent 30% of the final grade. </li> <li>Practical assignments (jupyter notebooks) are to be completed as indicated in each assignment description. Each of the course blocks will have one or more practical assignments. The assignments represent 50% of the final grade.</li> <li>A report on transversal issues: ethics, data protection, reliability, usability, acceptability (Work proposals) will be developed in groups representing 20% of the final grade. </li> </ul> <p>The source code of these pages, written in markdown for MkDocs, is available on GitHub.</p> <p>You can obtain a local copy of these pages (e.g., for offline access) by executing:</p> <pre><code>wget --mirror --no-parent --convert-links --page-requisites https://FranciscoFlorezRevuelta.github.io/EI\n</code></pre> <p>Please note that the content may change throughout the course.</p> <p>The course has the following blocks:</p> <ul> <li>16 April: Introduction to intelligent environments and applications (Francisco Fl\u00f3rez)</li> <li>16 April: Internet of Things (Pau Climent)</li> <li>30 April and 7 May: Computer vision for Active Assisted Living (Francisco Fl\u00f3rez)</li> <li>7 May: Multimodal interaction, datasets, and synthetic generation (Jose Garc\u00eda)</li> </ul>"},{"location":"AmI/","title":"Intelligent environments","text":""},{"location":"AmI/#objectives","title":"Objectives","text":"<ul> <li>Provide a deep understanding of Ambient Intelligence (AmI), exploring how AmI forms the theoretical and technological foundation for intelligent environments and enhanced living spaces.</li> <li>Examine the key technologies that drive AmI, including sensor technology, communication networks, user interface technology, data processing, AI, and actuator technology. We will also discuss how these technologies converge into AI, IoT, and Natural Interaction, shaping intelligent environments.</li> <li>Analyse how the principles and technologies of AmI are applied in various domains such as Ambient Assisted Living, smart cities, smart buildings, and smart industries. We aim to understand the practical implications and transformative potential of these applications.</li> <li>Critically assess the benefits of Ambient Intelligence in improving quality of life, efficiency, safety, and comfort. Concurrently, we will address the challenges, including privacy concerns, security risks, interoperability, and ethical considerations.</li> <li>Understand the regulatory, legal, and ethical frameworks relevant to Ambient Intelligence.</li> </ul>"},{"location":"AmI/#introduction","title":"Introduction","text":"<p>Ambient Intelligence (AmI) is a concept that deeply resonates with the pioneering work of Mark Weiser, often regarded as the father of ubiquitous computing. In the early 1990s, Weiser introduced a vision of computing where technology would seamlessly integrate into our everyday lives, becoming virtually invisible and yet omnipresent. This vision laid the groundwork for Ambient Intelligence, a paradigm where environments are sensitively, adaptively, and autonomously responsive to human presence and needs. Weiser\u2019s idea was not just about embedding computers everywhere but about creating a harmonious interplay between humans and technology, where the latter supports and enhances daily activities without being obtrusive. This philosophy is fundamental to AmI, which focuses on creating intelligent, intuitive, and context-aware systems that operate in the background, offering a more natural and user-friendly interaction with technology. </p> <p>Ambient Intelligence (AmI), Intelligent Environments (IE), and Enhanced Living Environments (ELE) are interconnected concepts within the domain of advanced technology, each contributing to a more intuitive, interactive, and user-centred approach to using technology in daily life.</p> <ul> <li> <p>Ambient Intelligence (AmI): This concept refers to the presence of a digital environment that is sensitive, adaptive, and responsive to the presence and needs of humans. Ambient Intelligence is characterised by its ubiquity, transparency, and intelligence. It integrates seamlessly into everyday life, providing a network of embedded devices and intelligent systems that work in the background to support human activities. AmI uses technologies like AI, machine learning, and IoT to anticipate needs and preferences, offering personalised and context-aware solutions.</p> </li> <li> <p>Intelligent Environments (IE): An Intelligent Environment is a broader term that encompasses any space, whether a room, a building, or even a city, where technology and connectivity are employed to enhance its functionality, efficiency, and inhabitants' experience. IEs are powered by integrated systems that include sensing, processing, and actuation technologies. This concept extends beyond mere automation to include environments that can sense conditions, interpret data, and act intelligently. Intelligent Environments overlap with Ambient Intelligence in their use of smart technology to create responsive and adaptive spaces.</p> </li> <li> <p>Enhanced Living Environments (ELE): This term often refers to the application of Ambient Intelligence and Intelligent Environments in the context of home and personal living spaces. The focus here is on improving the quality of life, health, and well-being of the inhabitants. ELEs make use of smart devices, home automation, and health monitoring systems to provide support, especially for older or disabled individuals, ensuring safety, comfort, and convenience. ELEs represent a specific application area of AmI and IEs, with a distinct focus on enhancing living conditions and health support.</p> </li> </ul> <p>In summary, Ambient Intelligence forms the theoretical and technological foundation upon which Intelligent Environments are built, and Enhanced Living Environments are a specific application domain of these concepts, focusing particularly on personal living spaces. All these concepts work towards creating a more intelligent, intuitive, and human-centred interaction with technology, improving everyday life, efficiency, safety, and comfort.</p> <p>Mandatory readings: </p> <ul> <li>Weiser, M. (1991). The Computer for the 21st Century. Scientific american, 265(3), 94-105. </li> <li>Augusto, J. C., Callaghan, V., Cook, D., et al. (2013). Intelligent Environments: a manifesto. Human-Centric Computing and Information Sciences, 3(12).</li> <li>Friedewald, M., &amp; Da Costa, O. (2003). Science and technology roadmapping: Ambient intelligence in everyday life (AmI@ Life) (pp. 1-197). Working Paper. Seville: Institute for Prospective Technology Studies IPTS. - Section 1. Introduction to Ambient Intelligence and Section 3. Application areas for Ambient Intelligence in  Everyday Life.</li> </ul> <p>Optional readings:</p> <ul> <li>Friedewald, M., &amp; Da Costa, O. (2003). Science and technology roadmapping: Ambient intelligence in everyday life (AmI@ Life) (pp. 1-197). Working Paper. Seville: Institute for Prospective Technology Studies IPTS. - Section 4. Enabling Technologies for Ambient Intelligence Applications and Section 6. Enabling and Constraining Factors.</li> <li>Ducatel, K., M. Bogdanowicz, F. Scapolo, J. Leijten &amp; J-C. Burgelman (2001) Scenarios for ambient intelligence in 2010. Seville: Institute for Prospective Technology Studies IPTS. (This is a very interesting document about what was foreseen to be the applications of AmI in 2010)</li> </ul>"},{"location":"AmI/#basic-principles","title":"Basic principles","text":"<p>The basic principles of Ambient Intelligence revolve around creating environments that are seamlessly integrated with technology to enhance human interaction and experience. These principles include:</p> <ul> <li> <p>Context awareness: AmI systems are designed to be aware of their environment and the context in which they operate. They can detect and interpret various factors, such as location, time of day, presence of people, and their activities or preferences.</p> </li> <li> <p>Ubiquity: Technology in AmI is ubiquitous, meaning it is present everywhere yet remains unobtrusive. This involves embedding technology in everyday objects and environments, making it an invisible yet integral part of users' lives.</p> </li> <li> <p>Sensitivity and responsiveness: AmI environments are sensitive to the presence and needs of individuals. They can respond dynamically to changes in the environment or user behaviour, adapting in real-time to provide the most appropriate support or service.</p> </li> <li> <p>Personalisation and adaptation: These systems are capable of learning from user interactions and preferences, allowing them to personalise experiences and adapt over time to meet individual needs more effectively.</p> </li> <li> <p>Anticipatory interaction: Ambient Intelligence aims to anticipate the needs and desires of its users, often even before the users themselves are explicitly aware of them. This proactive approach can enhance user experience and satisfaction.</p> </li> <li> <p>Seamless Interaction: AmI strives for seamless and natural interactions between humans and technology, minimizing the need for explicit commands or controls and enabling more intuitive, gesture or behaviour-based interfaces.</p> </li> <li> <p>Intelligent and autonomous operation: These systems are equipped with AI and machine learning capabilities, enabling them to operate intelligently and autonomously, often without direct human intervention.</p> </li> <li> <p>Privacy and security: Given the pervasive nature of AmI and its reliance on personal data, maintaining privacy and ensuring data security are fundamental principles, with systems designed to protect user information and trust.</p> </li> </ul>"},{"location":"AmI/#key-technologies","title":"Key technologies","text":"<p>Ambient Intelligence (AmI) is a sophisticated interplay of devices, systems, and methodologies designed to create environments that are not only smart and responsive but also intuitive and seamless in their interaction with users. </p> <p>Sensor technology forms the sensory network of AmI, providing real-time, contextual information essential for any intelligent system to understand and interact effectively with its surroundings. From temperature to motion and beyond, these sensors act as the eyes and ears of AmI, capturing crucial data that serve as the foundation for decision-making and actions.</p> <p>Communication networks, both wireless and wired, ensure that the wealth of data gathered by sensors is transmitted seamlessly for processing and action. These networks represent the arteries of information flow in AmI, enabling devices to communicate, share insights, and collaborate in real-time, thus forming an interconnected web of intelligence.</p> <p>User interface technology plays a fundamental role in AmI, acting as the bridge between humans and technology. It encompasses a range of interfaces from touchscreens to voice and gesture controls, ensuring that interaction with technology is natural, intuitive, and accessible.</p> <p>Central to the intelligence of these environments is data processing and AI. This technology processes the vast amounts of data collected, employs machine learning to understand patterns and preferences, and makes informed decisions. This capability is what enables AmI to be predictive, adaptive, and truly intelligent.</p> <p>Actuator technology is what turns the decisions and insights of AmI systems into physical action. Actuators are the effectors of AmI, directly manipulating the environment in response to intelligent analysis \u2014 be it adjusting lighting, temperature, or even initiating security protocols.</p> <p>The diverse and intricate technologies underpinning Ambient Intelligence can be encapsulated into three broad and interlinked categories: Artificial Intelligence (AI), the Internet of Things (IoT), and Natural Interaction. AI serves as the brain of AmI, endowing systems with the capability to process vast amounts of data, learn from user interactions, and make autonomous decisions. It is the intelligence that forecasts needs, adapts to preferences, and imbues environments with the ability to reason and respond dynamically. IoT acts as the nervous system, a network of interconnected devices and sensors that seamlessly collect, exchange, and act upon data, making the environment aware and interconnected. This framework allows for the synchronisation and orchestration of various components within the intelligent environment. Lastly, natural interaction represents the harmonious interface between humans and technology, encompassing user-friendly modalities like voice, touch, and gesture and activity recognition. It ensures that interactions with technology are intuitive and unobtrusive, aligning with human behaviours and preferences.</p>"},{"location":"AmI/#applications","title":"Applications","text":"<p>Ambient Intelligence finds its application across a wide spectrum of domains, each leveraging its potential to create environments that are more responsive, efficient, and attuned to human needs. One prominent application is in Ambient Assisted Living (AAL), where AmI technologies offer support and enhanced living conditions, particularly for older, frail, and disabled people, thus enabling them to lead independent and safer lives. Smart Cities stand out as how AmI can revolutionise urban living. Here, AmI principles are applied to manage traffic, conserve energy, improve public safety, and facilitate better urban planning, creating cities that are not only efficient but also sustainable and liveable. In the context of infrastructure, Smart Buildings utilise AmI to optimise energy use, maintain security, and enhance the comfort of their occupants, thereby embodying the very essence of intelligent and eco-friendly architecture. Additionally, Smart Industries represent another significant application where AmI drives the next wave of industrial revolution. By integrating AmI into industrial operations, processes become more efficient, adaptable, and safer, leading to increased productivity and reduced environmental impact. Across these diverse applications, the core idea of AmI remains constant \u2013 to seamlessly integrate intelligent technology into our surroundings, thereby improving the quality of our interactions with these environments.</p>"},{"location":"AmI/#ambient-assisted-living-aal","title":"Ambient Assisted Living (AAL)","text":"<p>Ambient Assisted Living (AAL) refers to a system where technology is integrated into the living environment to provide support, assistance, and care, particularly for older, frail, and disabled people. The primary goal of AAL is to enable these individuals to maintain their independence, improve their quality of life, and increase their safety and comfort at home. This is achieved through the seamless integration of various AmI technologies.</p> <p>The main objectives of AAL encompass a range of goals designed to significantly enhance the quality of life for older people and those requiring assistance: * Extend the time that people can live in their preferred environment, increasing their autonomy, confidence, and mobility. * Provide support for maintaining the health and functional abilities of older people. * Promote a better and healthier lifestyle for individuals at risk. * Improve safety, prevent social isolation, and support the maintenance of a multi-functional network around the individual. * Support caregivers, families, and care providers. * Increase the efficiency and productivity of resources used in aging societies.</p> <p>Mandatory readings: </p> <ul> <li>AALIANCE2 project (2014). D2.7a. Update and final version of the AALIANCE2 AAL Roadmap 2014 - Section 3. Needs and expectations in the ageing society, Section 5. AAL Service Areas and Scenarios, Section 6. Key Enabling Technologies.</li> </ul>"},{"location":"AmI/#smart-homes-and-smart-buildings","title":"Smart homes and smart buildings","text":"<p>Smart homes leverage the power of the Internet of Things (IoT), Artificial Intelligence (AI), and other technologies to create living spaces that are highly responsive to the needs and preferences of their inhabitants. These homes integrate systems such as automated lighting, climate control, security, and entertainment, all of which can be monitored and controlled remotely. The essence of a smart home lies in its ability to learn from the behaviours of its residents, adapting to optimise comfort and efficiency, and offering an unprecedented level of convenience and personalization.</p> <p>Smart buildings, extending beyond the individual household, encompass similar technologies on a larger scale. These structures are designed not only to provide enhanced comfort and convenience to their occupants but also to optimise their operational efficiency. Smart buildings are equipped with sensors and automation systems that manage everything from heating, ventilation, and air conditioning (HVAC) to energy consumption and space utilisation. By gathering and analysing data, these buildings can make intelligent decisions to reduce energy waste, lower operational costs, and minimise their environmental footprint.</p> <p>Mandatory readings:</p> <ul> <li>Sovacool, B. K., &amp; Del Rio, D. D. F. (2020). Smart home technologies in Europe: A critical review of concepts, benefits, risks and policies. Renewable and sustainable energy reviews, 120, 109663.</li> <li>Al Dakheel, J., Del Pero, C., Aste, N., &amp; Leonforte, F. (2020). Smart buildings features and key performance indicators: A review. Sustainable Cities and Society, 61, 102328.</li> </ul>"},{"location":"AmI/#smart-cities","title":"Smart cities","text":"<p>Smart cities represent a revolutionary approach in urban development, harnessing the power of advanced technologies to transform the way we live, work, and interact within urban environments. At the core of this concept is the integration of the Internet of Things (IoT), data analytics, artificial intelligence, and other digital technologies to create cities that are not only more efficient and sustainable but also more responsive to the needs and well-being of their residents. Smart cities are characterised by their ability to use technology to improve infrastructure, public services, and urban governance. This includes optimising traffic and transportation systems, enhancing energy utilisation, improving waste management, and ensuring public safety. Furthermore, smart cities focus on fostering stronger engagement between the government and citizens, enhancing the quality of life through innovative solutions. By effectively analysing and utilising the wealth of data generated within urban spaces, smart cities pave the way for a future where urban living is more connected, sustainable, and citizen-centric.</p> <p>Mandatory readings:</p> <ul> <li>Law, K. H., &amp; Lynch, J. P. (2019). Smart city: Technologies and challenges. IT Professional, 21(6), 46-51.</li> </ul>"},{"location":"AmI/#smart-industry","title":"Smart industry","text":"<p>Smart industry, often synonymous with Industry 4.0, marks a significant evolution in the manufacturing and industrial area, driven by the integration of digital technologies into industrial processes. At the heart of this revolution is the seamless combination of physical production and operations with smart digital technology, machine learning, and big data. This integration leads to intelligent, autonomous systems capable of self-optimisation and decision-making. Smart Industry is characterised by its highly efficient, flexible, and adaptable manufacturing processes, enabled by technologies such as the Internet of Things (IoT), Cyber-Physical Systems (CPS), robotics, and cloud computing. These technologies facilitate real-time monitoring and control of industrial processes, significantly enhancing productivity, reducing operational costs, and improving workplace safety. Additionally, Smart Industry embraces the concept of the digital twin \u2013 virtual replicas of physical systems that can be used for simulation and analysis \u2013 to further refine and optimise processes. As a result, Smart Industry not only transforms production lines but also reshapes entire business models, paving the way for more sustainable, resilient, and customised production solutions.</p> <p>Mandatory reading:</p> <ul> <li>Xu, L. D., Xu, E. L., &amp; Li, L. (2018). Industry 4.0: state of the art and future trends. International journal of production research, 56(8), 2941-2962.</li> </ul> <p>Optional reading:</p> <ul> <li>Sigov, A., Ratkin, L., Ivanov, L. A., &amp; Xu, L. D. (2022). Emerging enabling technologies for industry 4.0 and beyond. Information Systems Frontiers, 1-11.</li> </ul>"},{"location":"AmI/#benefits-and-challenges","title":"Benefits and challenges","text":"<p>Ambient Intelligence offers a range of benefits that significantly contribute to enhancing the quality of life, efficiency, and overall experience of individuals in various environments. Here are some of the key benefits:</p> <ul> <li> <p>Enhanced quality of life: AmI aims to make everyday life more comfortable and convenient. By integrating technology seamlessly into the environment, it simplifies daily tasks, reduces the need for manual intervention, and provides support according to individual preferences and needs.</p> </li> <li> <p>Personalisation: One of the most significant advantages of AmI is its ability to personalise experiences. Systems can learn and adapt to individual user behaviours and preferences, offering a highly customised environment. This is particularly beneficial in settings like smart homes or personalised healthcare.</p> </li> <li> <p>Seamless and intuitive interaction: By enabling natural and intuitive interaction with technology, such as voice commands, gesture control, and context-aware interfaces, AmI reduces the complexity and learning curve associated with new technologies.</p> </li> <li> <p>Real-time data and decision making: AmI systems provide real-time data processing and decision-making capabilities, which are essential in dynamic environments like traffic management in smart cities or critical industrial processes.</p> </li> <li> <p>Increased efficiency and sustainability: AmI contributes to more efficient use of resources, such as energy and water, by automating control and optimizing usage based on real-time data. This not only reduces costs but also minimises environmental impact, contributing to sustainability.</p> </li> <li> <p>Improved safety and security: AmI environments can enhance safety and security through automated monitoring and response systems. For example, in a smart home, the system can detect potential hazards like gas leaks or unauthorised entry and take immediate action.</p> </li> <li> <p>Support for older and disabled people: AmI has significant implications for healthcare, particularly in supporting older and disabled individuals. By monitoring health and providing assistance with daily activities, AmI can help these individuals maintain independence and improve their quality of life.</p> </li> <li> <p>Better healthcare delivery: In healthcare settings, AmI can provide continuous monitoring of patients, real-time data analysis, and prompt response to medical conditions, leading to improved patient care and outcomes.</p> </li> <li> <p>Efficient and comfortable work environments: In workplace settings, AmI can optimise environmental conditions, like lighting and temperature, and facilitate efficient resource management, leading to more comfortable and productive work environments.</p> </li> </ul> <p>While Ambient Intelligence offers significant benefits, it also faces various challenges that need to be addressed to fully realise its potential:</p> <ul> <li> <p>Privacy concerns: AmI systems rely heavily on collecting and processing personal data to provide personalised services. This raises significant privacy concerns, as sensitive information could be misused if not properly protected.</p> </li> <li> <p>Security risks: The interconnected nature of AmI environments makes them susceptible to cybersecurity threats. Unauthorised access, data breaches, and hacking can pose serious risks to both functionality and user safety.</p> </li> <li> <p>Interoperability: As AmI systems often involve a wide array of devices and platforms, ensuring they can work together seamlessly is a significant challenge. Interoperability standards are needed to ensure smooth integration.</p> </li> <li> <p>Technical limitations: Challenges such as limited battery life of sensors, data transmission issues, and the processing power needed for real-time analytics can hinder the effectiveness of AmI systems.</p> </li> <li> <p>Data management and analysis: The vast amount of data generated by AmI environments requires efficient management and analysis, posing challenges in terms of data storage, processing capabilities, and ensuring real-time response.</p> </li> <li> <p>High costs: The development and deployment of AmI technologies can be costly. The expenses related to advanced sensors, AI systems, and secure networks can be a barrier, particularly in large-scale implementations.</p> </li> <li> <p>User acceptance and adaptation: Users might be skeptical or uncomfortable with pervasive monitoring and automated decision-making. Ensuring user acceptance and trust is crucial for the successful adoption of AmI.</p> </li> <li> <p>Ethical and societal issues: AmI technologies raise ethical questions, particularly regarding autonomy, consent, and the potential for over-reliance on technology in daily life. Societal impact, such as potential job displacement due to automation, also needs consideration.</p> </li> <li> <p>Regulatory and legal challenges: There is a need for clear regulatory frameworks and legal guidelines to address issues related to data protection, liability, and standards in AmI environments, which are often not yet fully established.</p> </li> </ul> <p>Addressing these challenges is crucial for the successful integration and acceptance of Ambient Intelligence in everyday life, ensuring that it not only enhances user experience but also respects privacy, security, and ethical norms.</p> <p>Mandatory viewings:</p> <ul> <li>What is the GDPR? | A summary of the EU GDPR</li> </ul> <p>Mandatory readings: </p> <ul> <li>High-level summary of the AI Act</li> <li>GoodBrother COST Action (2022). State of the art on ethical, legal, and social issues linked to audio- and video-based AAL solutions.</li> <li>GoodBrother COST Action (2022). State of the art in privacy preservation in video data - Section 2. Privacy by design.</li> </ul> <p>Optional readings:</p> <ul> <li>AI Act</li> <li>General Data Protection Regulation</li> </ul>"},{"location":"AmI/#moodle-test","title":"Moodle test","text":"<ul> <li>The moodle test will be developed during practice sessions on Wednesday 16 April at 4.30pm CET.</li> <li>The test has a maximum duration of 30 minutes from the start.</li> <li>The test consists of 20 triple choice questions.</li> <li>Each wrong answer subtracts 1/3 of the value of a correct answer.</li> <li>The mark for the test will be considered as one of the marks for the theoretical part of the course. See the overall evaluation of the course in the general conditions.</li> <li>The questions will be based on this webpage and all the mandatory readings proposed. The test will also include questions about the module on the Internet of Things.</li> </ul>"},{"location":"CV-AAL-lab/","title":"Gait analysis","text":""},{"location":"CV-AAL-lab/#introduction","title":"Introduction","text":"<p>Gait analysis is a comprehensive assessment of the way an individual walks or runs, used primarily to highlight any abnormalities in gait patterns that could be indicative of underlying health issues. This type of analysis meticulously captures biomechanical data to evaluate different aspects such as stride length, speed, and body symmetry during movement. Technological advancements have enabled sophisticated methodologies in gait analysis, utilising sensors and cameras to provide precise, quantitative data. This analysis is crucial not only in sports and rehabilitation but also in diagnosing conditions like Parkinson's disease, arthritis, and musculoskeletal disorders, where changes in gait can be some of the first signs of disease progression.</p> <p>In the context of Ambient Assisted Living (AAL), gait analysis holds significant relevance as it offers a non-intrusive means of continuous monitoring that can alert caregivers and healthcare providers to changes in an older person's mobility and balance. Regular monitoring of gait can identify early signs of decline in physical function, which is often a precursor to falls \u2014a major risk for elderly individuals. Integrating gait analysis into AAL systems leverages technology to ensure safety and support for older people, enabling early intervention and facilitating aging in place with dignity. This technology not only enhances the ability to live independently but also supports preventive health measures, improving overall quality of life.</p> <p>Computer vision for gait analysis is a significant advancement in assessing walking patterns, utilising image processing and machine learning to detect and analyse human motion. This technology captures real-time video data, which is then processed to extract key information about gait characteristics such as stride length, gait speed, and postural control. The application of computer vision in gait analysis allows for precise and accurate assessment without the need for physical contact or invasive markers on the body. This approach is particularly useful in settings where continuous monitoring is essential, offering an efficient, scalable, and less obtrusive method to assess mobility and balance. Consequently, computer vision has become an invaluable tool in clinical diagnostics, rehabilitation, and elderly care, providing insights that can guide treatment plans, monitor recovery, and prevent falls by identifying potential mobility issues before they result in serious injuries.</p>"},{"location":"CV-AAL-lab/#the-psymo-dataset","title":"The PsyMo dataset","text":"<p>The PsyMo dataset is a comprehensive multi-modal dataset designed to investigate psychological traits manifested in walking patterns. Developed by researchers from the University Politehnica of Bucharest, it features data from 312 participants who walked in seven different styles, captured from six camera angles. In addition to motion data, the dataset includes self-reported psychological traits from six different questionnaires covering aspects like personality, self-esteem, fatigue, aggression, and mental health. PsyMo, which stands for Psychological traits from Motion, offers anonymised data including silhouettes, 2D and 3D human skeletons, and 3D SMPL human meshes, making it a rich resource for both psychological and gait analysis research.</p> <p>The Psymo dataset was presented at the 2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV). The paper is available here.</p>"},{"location":"CV-AAL-lab/#lab-session-implementing-deep-learning-for-gait-analysis-using-the-psymo-dataset","title":"Lab session - Implementing deep learning for gait analysis using the PsyMo dataset","text":"<p>This lab session aims to provide students with practical experience in applying deep learning techniques to analyze gait patterns using the PsyMo dataset. The session will focus on developing models that can interpret variations in walking styles associated with different psychological traits.</p>"},{"location":"CV-AAL-lab/#tasks","title":"Tasks","text":"<ol> <li> <p>Data exploration:</p> <ul> <li>Familiarise yourself with the dataset structure. See this file</li> <li>Visualise different modalities of gait data (silhouettes, skeletons). See folder semantic_data.</li> <li>Analyse files with labels (metadata_labels_v3.csv, metadata_raw_scores_v3.csv, walks-v2.csv).</li> </ul> </li> <li> <p>Preprocessing:</p> <ul> <li>Implement data cleaning and normalisation techniques.</li> <li>Generate training and testing splits ensuring a balanced representation of walking styles and psychological traits. </li> </ul> </li> </ol> <p>The authors propose subjects with IDs from 0-250 should be used for training, and evaluation ought to be performed on subjects with IDs from 251-312, corresponding to an 80:20 training-evaluation split. However, in most cases, you will not have enough computing capabilities to train the whole dataset. Therefore, I recommend that for implementation and preliminary tests, you use a reduced subset, following the same percentages. For instance, subjects with IDs 0-8 for training, and 251-252 for evaluation. You can adjust these numbers based on your computing capability. You can download a reduced version of the dataset from here (subjects 0-7 for training, 8-9 for testing).</p> <ol> <li> <p>Model building:</p> <ul> <li>Choose an appropriate deep learning architecture.</li> <li>Develop a model to correlate gait patterns with psychological traits.</li> <li>Utilise transfer learning, if applicable, to leverage pre-trained models on similar tasks.</li> </ul> </li> </ol> <p>Here, you need to propose a deep learning architecture to correlate gait patterns with psychological traits. You have here several alternatives:  1. Use an existing model (like OpenGait, GaitGraph or any of the others used by the authors) - See Table 2 in their paper. 2. Propose a new model. For instance, using Video Vision Transformers, Graph Convolutional Networks, 3D ConvNets, Inflated 3D ConvNets,...) - See the module on Video-based human action/activity recognition. The authors propose two evaluation methodologies: (i) run-level and (ii) subject-level. For run-level evaluation, the model performance is evaluated for each walking sequence, irrespective of the subject. Performance in terms of precision, recall, weighted F1 score should be reported for all combinations of walking variations and viewpoints. This protocol is similar to a typical gait classification task (i.e. input walking sequence, output classes). For subject-level evaluation, the goal is to correctly identify the psychometric attributes for each subject, considering all available variations or runs. For instance, a naive baseline for subject-level evaluation is to use the run-level model and report the majority predicted classes for a questionnaire for all the runs of a subject. Methods for subject-level evaluation may consider the identity of the subject to be known at test time - a scenario possible in the real-world, as a part of a larger pipeline for gait recognition and classification. The same metrics as in run-level evaluation should be used. 3. Merge an existing model with some additional inputs.</p> <ol> <li> <p>Training:</p> <ul> <li>Train the model using the prepared dataset.</li> </ul> </li> <li> <p>Evaluation:</p> <ul> <li>Evaluate the model performance using appropriate metrics (e.g., accuracy, F1-score).</li> </ul> </li> <li> <p>Discussion and Reporting:</p> <ul> <li>Interpret the results and discuss the implications of the findings.</li> <li>Prepare a brief report summarising the methodology, results, and potential improvements.</li> </ul> </li> </ol>"},{"location":"CV-AAL-lab/#timeline","title":"Timeline","text":"<ul> <li>This lab session will take place on Wednesday 30 April 4pm to 9pm and on Wednesday 7 May 4pm to 6pm.</li> <li>Dedicate a maximum of 16.5 hours to this work. This includes time at home. If you are not able to finish all the tasks, please, report it in the final report.</li> <li>If you work more than those 16.5 hours, please, specify the amount of time worked.</li> <li>Code (for instance, a link to a Colab notebook) and brief report must be provided through the Evaluation option at UACloud by Wednesday 14 May 11.59pm. </li> </ul>"},{"location":"CV_AAL/","title":"Computer vision for AAL","text":""},{"location":"CV_AAL/#introduction","title":"Introduction","text":"<p>Ambient Assisted Living (AAL) systems are designed to enhance the quality of life and promote independent, healthy living for elderly or disabled individuals through the integration of information and communication technologies. These systems are implemented in homes, workplaces, and public areas, and are equipped with a variety of sensors. These sensors may be embedded in the environment or worn by the user, gathering data on both the environment and the individual to facilitate interactions between the person and their surroundings. The data collected are analyzed by expert and intelligent systems to deliver advanced, personalized healthcare services.</p> <p>Advancements in wearable computing technology, such as wearable cameras, smartwatches, wristbands, and glasses, along with the increased functionality of mobile devices and health apps, support the design, development, and wider adoption of healthcare and assisted living services. Technologies like lifelogging enable users to continuously collect data about themselves, their environments, and their interactions, fostering greater health, well-being, and independence. This ongoing data acquisition, including physiological signals (heart rate, respiratory rate, body temperature, skin conductance), motion, location, activities, visual and auditory inputs, underpins a range of innovative services. These services offer personalized healthcare, wellness monitoring (including physical activity and dietary habits), support for individuals with memory impairments, enhanced social participation and mobility, assistance for both formal and informal caregivers, and predictive systems for monitoring cognitive decline, aggressive behaviors, and preventing falls.</p> <p>Recent advancements in intelligent systems and computer vision have enhanced Ambient Assisted Living (AAL) technologies, particularly through the integration of camera systems. These cameras provide more comprehensive sensory information compared to traditional sensors used in AAL systems, such as magnetic sensors, presence sensors, and pressure mats. Typically, AAL systems employ conventional \"third person\" vision systems where cameras are strategically placed within the environment to monitor individuals. An alternative approach involves mounting a camera on the head or torso of a person to capture activities from an egocentric perspective\u2014that is, from the individual's own point of view. This method offers a more direct and personal viewpoint, enhancing the monitoring and support capabilities of AAL systems.</p>"},{"location":"CV_AAL/#video-based-aal-applications","title":"Video-based AAL applications","text":"<p>Video-based Ambient Assisted Living (AAL) applications are increasingly becoming a crucial component of care for the older and disabled people, utilising advanced video processing and computer vision technologies to provide a range of supportive services. Here are some specific applications of video-based AAL:</p> <ul> <li> <p>Fall detection and alert systems: One of the most critical applications of video-based AAL is in detecting falls, which are a major risk for older individuals. Using cameras installed in a home, these systems analyse the person\u2019s movements and use machine learning algorithms to recognise patterns that indicate a fall. Immediate alerts are sent to caregivers or emergency services, ensuring rapid response to potentially serious incidents.</p> </li> <li> <p>Activity monitoring: Video-based systems can continuously monitor the activities of daily living and provide insights into the behavioural patterns of residents. By analysing these patterns, the system can detect deviations that may indicate health issues or deteriorating conditions, such as reduced mobility, changes in eating habits, or increased restlessness during sleep.</p> </li> <li> <p>Health monitoring: Advanced video analytics can extract subtle physiological signals, such as skin color changes that may indicate fluctuations in blood pressure or heart rate. This non-invasive monitoring can offer valuable health insights without the need for wearable devices, providing a comfortable and unobtrusive way to keep track of a resident's health status.</p> </li> <li> <p>Safety enhancements: Video surveillance can ensure that areas like kitchens and bathrooms are used safely by individuals with cognitive impairments or physical limitations. It can detect risky behaviors, such as leaving the stove on or slipping in the bathroom, and alert caregivers to intervene.</p> </li> <li> <p>Social interaction facilitation: Some video-based AAL systems use emotion recognition algorithms to assess the mood and emotional state of the individual. This information can help caregivers adjust daily activities and interactions to better suit the resident\u2019s emotional needs, enhancing their quality of life and reducing feelings of isolation.</p> </li> <li> <p>Memory aid and support: For individuals suffering from memory loss due to conditions like Alzheimer\u2019s, video-based systems can act as a memory aid by providing reminders and cues about daily tasks and routines. By recognising the context and the individual\u2019s actions, the system can prompt when it\u2019s time to take medication, attend appointments, or perform other necessary daily activities.</p> </li> </ul> <p>These applications not only enhance the autonomy and safety of individuals living in AAL environments but also significantly relieve the burden on caregivers by providing reliable and continuous monitoring and support. As technology advances, video-based AAL systems are set to become even more sophisticated, integrating seamlessly into the lives of users and offering an even wider range of services to improve their well-being and independence.</p> <p>Mandatory readings: </p> <ul> <li>GoodBrother COST Action (2022). State of the art on ethical, legal, and social issues linked to audio- and video-based AAL solutions. Section 3.1. Video-based sensing technologies, Section 3.3.1 Main challenges for data processing, Section 3.4. Multimodal data fusion for AAL, Section 4. AAL applications: recent advances in successful assistive and supportive functions (NOTE: do not read sections on the use of audio-based devices).</li> </ul> <p>Optional reading:</p> <ul> <li>Climent-P\u00e9rez, P., Spinsante, S., Mihailidis, A., &amp; Florez-Revuelta, F. (2020). A review on video-based active and assisted living technologies for automated lifelogging. Expert Systems with Applications, 139, 112847.</li> </ul>"},{"location":"CV_AAL/#concerns-on-the-use-of-cameras-for-aal","title":"Concerns on the use of cameras for AAL","text":"<p>The integration of cameras in AAL technologies is seen as transformative for the future healthcare and wellness markets, offering smart enhancements for daily living environments. However, these devices are often perceived as intrusive by some end-users, professionals, and caregivers, raising significant concerns about privacy, psychological well-being, and social behaviour. These concerns necessitate an ethical approach and a comprehensive understanding of surveillance ethics, as AAL poses several ethical challenges that could impact acceptance and long-term usage. Issues such as data monitoring, storage, sharing, and the exacerbation of social inequalities highlight the need for ethical considerations in AAL design, including beneficence, non-maleficence, respect for autonomy, and data confidentiality.</p> <p>Legally, AAL must adhere to existing frameworks concerning product safety, data protection, cybersecurity, and intellectual property, with specific regulations like the AI Acti, GDPR and Medical Device Regulation providing guidelines that are challenging to implement due to their evolving nature. Socially, AAL technologies must address potential increases in loneliness and isolation among vulnerable groups and ensure that they do not reinforce existing power asymmetries or social disadvantages. The development of AAL technologies must also consider varying needs and motivations across different demographics to avoid creating additional technological burdens and governance challenges.</p> <p>Mandatory reading: </p> <ul> <li>Ravi, S., Climent-P\u00e9rez, P., &amp; Florez-Revuelta, F. (2024). A review on visual privacy preservation techniques for active and assisted living. Multimedia Tools and Applications, 83(5), 14715-14755. (except Section 6. Performance evaluation)</li> </ul>"},{"location":"CV_AAL/#additional-resources","title":"Additional resources","text":"<p>You can, optionally, access this presentation on computer vision for active assisted living. It includes videos on different applications of computer vision for active assisted living.</p>"},{"location":"CV_AAL/#moodle-test","title":"Moodle test","text":"<ul> <li>The moodle test will be developed during practice sessions on Wednesday 30 April at 4.30pm CET.</li> <li>The test has a maximum duration of 30 minutes from the start.</li> <li>The test consists of 17 triple choice questions.</li> <li>Each wrong answer subtracts 1/3 of the value of a correct answer.</li> <li>The mark for the test will be considered as one of the marks for the theoretical part of the course. See the overall evaluation of the course in the general conditions.</li> <li>The questions will be based on this webpage and all the mandatory readings proposed.</li> </ul>"},{"location":"IoT/","title":"Exploring IoT Technologies in ambient intelligence","text":"<p>Pau Climent-P\u00e9rez April, 2024</p> <p>\"The most profound technologies are those that disappear. They weave themselves into the fabric of everyday life until they are indistinguishable from it.\" -- Late Mark Weiser, who was the chief scientist at Xerox PARC</p>"},{"location":"IoT/#a-brief-recap-on-ambient-intelligence","title":"A brief recap on Ambient Intelligence","text":"<p>As we said when defining Ambient Intelligence, it is:</p> <p>Definition</p> <p>\u201cAmbient intelligence is the concept of capturing and processing data through sensors, processors, and actuators unobtrusively embedded throughout the environment. Leveraging artificial intelligence (AI), ambient systems provide connected, seamless, uninterrupted everyday experiences that require no human intervention.\u201d</p> <p>Optional read: https://www.arm.com/glossary/ambient-intelligence</p> <p>If we take the definition and break it down, we see that the following concepts emerge:</p> <ol> <li>We need sensors, processors, and actuators that are unobtrusively embedded in the environment</li> <li>The data of the sensors will be captured and processed</li> <li>It requires an automated machine-based intelligence (AI) to make decisions on the captured data (automated knowledge extraction)</li> <li>It is connected, and works seamlessly and continuously requiring no human intervention</li> </ol> <p>Therefore, one of the main characteristics of ambient intelligence (AmI for short) is the need for embedded sensors that are unobtrusive and can integrate naturally in the environment. The following figure<sup>1</sup> shows the main characteristics of AmI (left), and how these can be achieved using certain technologies (right). The Internet of Things (IoT, for short) appears as a clear component.</p> <p></p>"},{"location":"IoT/#ami-for-active-and-healthy-ageing-ami-4-aha","title":"AmI for Active and Healthy Ageing (AmI 4 AHA)","text":"<p>Ambient intelligence has many applications, such as in transportation, workplace improvement, smart homes, etc. It can be used to increase comfort, as well as to improve energy efficiency, or raise alarms when a hazard or a danger arises.</p> <p>However, given the ageing population in most countries, Active and Assisted Living (previously Ambient Assisted Living) arises as a concept that integrates IT technologies for improved care of older adults. With older populations needing higher levels of care provision, it is necessary to implement technologies that aid in independent living for longer. Also, this brings the opportunity to use human resources more efficiently (fewer carers available per older adult).</p> <p>When desigining AmI4AHA (AAL) systems, it is therefore of paramount importance to take a systematic approach<sup>2</sup> :</p> <p></p> <p>It is important to base the sensor selection (step 1) on the functional requirements of the system, and then use acquire the data that is necessary (step 2), processing it using ML/AI-based recognition algorithms (step 3) for data analysis and knowledge extraction, which can then be fed in long-term (temporal analysis) algorithms (step 4).</p> <p>Important</p> <p>Mandatory reading: Cicirelli et al. 2021 \"Ambient Assisted Living: A Review of Technologies, Methodologies and Future Perspectives for Healthy Aging of Population\" http://dx.doi.org/10.3390/s21103549</p> <p>In the case of a home for older adults, many needs can emerge, regarding reminder tools, aids for activities of daily living (ADLs), as well as other medical and disease prevention interventions. One example is shown next<sup>2</sup> :</p> <p></p> <p>The example integrates everyday tools such as smart vacuum robots, but also wearable location sensors, health-related wearable devices (heart rate, blood pressure, temperature), microphones for interaction with voice assistant and communications, blinds equipped with actuators for opening and closing them remotely, environmental sensors to sense ambient humidity and temperature (or air quality, CO$_2$), presence sensors for the detection of inhabitants, surveillance cameras (for security<sup>3</sup>, but also for safety<sup>4</sup>)</p>"},{"location":"IoT/#introduction-to-the-internet-of-things-iot","title":"Introduction to the Internet of Things (IoT)","text":""},{"location":"IoT/#but-what-is-iot","title":"But, what is IoT?","text":"<p>Apart from a main component of AmI, IoT can be described as the network of everyday \"things\" (appliances, small devices, electronics; but also parcels, unfinished products in a factory, product parts), that are embedded with sensors (i.e. made smart) and given the possibility to communicate with other devices, and the Internet. Put another way:</p> <p>Definition</p> <p>\"[...] (IoT) describes the network of physical objects\u2014\u201cthings\u201d\u2014that are embedded with sensors, software, and other technologies for the purpose of connecting and exchanging data with other devices and systems over the internet.\"</p> <p>Important</p> <p>Mandatory reading: https://www.oracle.com/internet-of-things/what-is-iot/ focus on Industrial IoT, or IIoT</p> <p>Similarly, there is also the idea that the devices of IoT are based on \"cheap\" integrated circuits (ICs), with the capability of Internet connection (i.e. a minimal TCP/IP stack, Bluetooth or other protocols):</p> <p>Definition</p> <p>\"The term IoT [...] refers to the collective network of connected devices and the technology that facilitates communication between devices and the cloud, as well as between the devices themselves. Thanks to the advent of inexpensive computer chips and high bandwidth telecommunication, we now have billions of devices connected to the internet. This means everyday devices like toothbrushes, vacuums, cars, and machines can use sensors to collect data and respond intelligently to users.\"</p> <p>Important</p> <p>Read the full article (mandatory): https://aws.amazon.com/what-is/iot/ focus on industrial and other applications</p> <p>In summary, instead of focusing on the deployment of sensors in the environment, and the processing of captured data and subsequent analysis (ambient intelligence), a particular focus is given to the devices themselves, and how these interact with each other.</p>"},{"location":"IoT/#components-of-an-iot-ecosystem","title":"Components of an IoT ecosystem","text":""},{"location":"IoT/#1-edge-computing","title":"1. Edge computing","text":"<p>Edge computing refers to the paradigm of processing data closer to its source, typically at or near the edge of the network, rather than relying solely on centralized cloud servers. By bringing computation and data storage closer to where it's needed, edge computing reduces latency, minimizes bandwidth usage, and enhances efficiency in data processing. </p> <p>This distributed computing approach enables faster response times and real-time analysis, making it ideal for applications that require immediate processing and decision-making, such as IoT devices, autonomous vehicles, and smart sensors. Edge computing also offers greater privacy and security by processing sensitive data locally, without necessarily transmitting it to the cloud. That is, edge computing revolutionizes the way data is managed and processed in the era of interconnected devices and decentralized computing architectures.</p>"},{"location":"IoT/#2-cloud-computing","title":"2. Cloud computing","text":"<p>This concept is perhaps the most well-known of the three, and refers to the delivery of computing services\u2014including storage, databases, servers, networking, software, and analytics\u2014over the internet (i.e. \"the cloud\") to offer faster innovation, flexible resources, and economies of scale. In the context of IoT, cloud computing plays a pivotal role in handling the massive amounts of data generated by interconnected devices. IoT devices collect and transmit data to cloud servers for storage, processing, and analysis.</p> <p>Cloud platforms provide the necessary infrastructure and services to manage and analyse IoT data efficiently, enabling businesses and organizations to derive valuable knowledge, optimize operations, and deliver enhanced services. Moreover, cloud computing facilitates scalability and accessibility, allowing IoT applications to expand and reach a broader audience without significant infrastructure investments. The integration of cloud computing and IoT fosters innovation and drives the development of intelligent solutions across various industries, from smart homes and cities to healthcare and manufacturing.</p>"},{"location":"IoT/#3-machine-learning-mlai","title":"3. Machine learning (ML/AI)","text":"<p>Machine learning is a subset of artificial intelligence (AI) that focuses on the development of algorithms and statistical models to enable computer systems to learn from and make predictions or decisions based on data, without being explicitly programmed for each task. In the context of IoT, machine learning is the component capable of extracting meaningful knowledge from the vast amounts of data generated by interconnected devices. By analysing patterns, trends, and anomalies in IoT data, machine learning algorithms can identify correlations, predict future outcomes, and automate decision-making processes.</p> <p>Machine learning empowers IoT systems to detect and respond to events in real-time, creating proactive systems, intelligent automations, and predictive analytics across various domains, from smart agriculture and industrial IoT to healthcare and smart cities. The integration of machine learning with IoT unleashes the full potential of connected devices, driving innovation, and transforming industries with intelligent, data-driven solutions.</p>"},{"location":"IoT/#what-is-fog-computing","title":"What is 'fog' computing?","text":"<p>Edge vs. cloud vs. fog, explained:</p>"},{"location":"IoT/#iot-protocols-and-standards","title":"IoT Protocols and Standards","text":"<p>There are several common IoT protocols and standards used for communication between devices, networks, and platforms in IoT ecosystems.</p> <p></p> <p>The figure above shows the 12 top ones, which we can classify into two main groups, depending on whether they are used for network connectivity (i.e. the network infrastructure itself), or they are used as part of a message passing or web API protocol that is more reduced in size, computational and bandwidth requirements than typical full-sized devices:</p>"},{"location":"IoT/#network-infrastructure","title":"Network infrastructure","text":"<ol> <li>Wi-Fi</li> <li>Bluetooth and Bluetooth Low Energy (BLE)</li> <li>Cellular (GSM, 2G/3G, 4G/LTE, 5G)</li> <li>Long range and LoRaWAN</li> <li>Zigbee</li> <li>Z-Wave</li> </ol>"},{"location":"IoT/#message-passing-web-apis-queuing-and-middleware","title":"Message passing, web APIs, queuing and middleware","text":"<ol> <li>MQTT (\"Mosquito\"): Message Queuing Telemetry Transport</li> <li>AMQP: Advanced Message Queuing Protocol</li> <li>DDS: Data distribution service</li> <li>CoAP: Constrained Application Protocol</li> <li>EMPP: Extensible Messaging and Presence Protocol</li> <li>LM2M: Lightweight Machine-to-Machine</li> </ol> <p>Important</p> <p>Read the article (mandatory) at: https://www.techtarget.com/iotagenda/tip/Top-12-most-commonly-used-IoT-protocols-and-standards</p> <p>These protocols and standards provide the foundation for interoperability, scalability, and reliability in IoT deployments, enabling seamless communication and integration across diverse devices, networks, and platforms in IoT ecosystems. Choosing the right protocol depends on factors such as device capabilities, network constraints, scalability requirements, and application-specific needs. An example of this is the use of Zigbee devices in smart homes, which frees up space in the Wi-Fi channel for communication of larger devices (less IPs assigned). Furthermore, Zigbee devices can be battery powered, with batteries lasting in the range of years, rather than weeks or months.</p>"},{"location":"IoT/#iot-hubs-and-gateways-making-different-protocols-work-together","title":"IoT hubs and gateways: making different protocols work together","text":"<p>IoT gateways and hubs allow IoT devices connected in a local network to interact with cloud services, they perform protocol translation (e.g. Zigbee message to HTTP web service request) as part of their protocol interoperability functions, data can be aggregated before it is sent, which reduces bandwidth usage. When they do so, as said above they perform edge or fog computing. As part of their implementation, they need to provide enhanced security to the local network, avoiding unauthorized access to the local IoT devices.</p> <p>Example</p> <p>Commercially available products, such Amazon echo integrate gateway capabilities. This type of device can find local Zigbee and Wi-Fi home sensors and integrate them. When a voice command is issued by the user, the voice assistant connects to Amazon AWS, and performs the command recognition, which then sends back requests for actuator changes, etc.</p> <p>Open source projects, such as Home Assistant https://www.home-assistant.io/ go even further, acting as a gateway that enables commercial products to interact with each other even when manufacturers do not support competitors' devices</p>"},{"location":"IoT/#sensors-and-actuators-in-iot","title":"Sensors and Actuators in IoT","text":"<p>Definition</p> <p>\"Sensors are devices that convert physical activity or changes into an electrical signal, while actuators are transducers that take one form of energy as input and produce some form of motion, movement, or action\"</p> <p>Read more (optional read): https://www.sciencedirect.com/topics/computer-science/sensors-and-actuator#definition</p>"},{"location":"IoT/#sensor-types-in-iot","title":"Sensor types in IoT","text":"<p>In Ambient Intelligence (AmI) environments, a variety of sensors are utilized to collect data about the physical world, human activities, and environmental conditions. These sensors play a crucial role in enabling intelligent systems to perceive, understand, and adapt to their surroundings. The following are some of the most common sensors utilized:</p> <ol> <li> <p>Motion Sensors: Motion sensors detect movement within their field of view using technologies such as passive infrared (PIR), ultrasonic, or microwave sensors. They are commonly used in smart home security systems, occupancy detection, and activity monitoring.</p> <ul> <li>Some examples are:<ul> <li>Texas Instruments (mmWave): https://www.ti.com/lit/spyy005</li> <li>Most common PIR sensor: https://learn.adafruit.com/pir-passive-infrared-proximity-motion-sensor/overview</li> </ul> </li> </ul> </li> <li> <p>Temperature and Humidity Sensors: These sensors measure ambient temperature and humidity levels. They are vital for climate control systems, energy management, and environmental monitoring in smart buildings.</p> <ul> <li>Examples:<ul> <li>The DHT11: https://learn.adafruit.com/dht/overview</li> <li>Flood detection: https://www.shelly.com/en-us/products/shop/shelly-flood-1</li> </ul> </li> </ul> </li> <li> <p>Light Sensors: Light sensors, such as photodiodes or photoresistors, measure the intensity of ambient light. They are used for automatic lighting control, daylight harvesting, and optimizing energy usage in indoor and outdoor lighting systems.</p> <ul> <li>Examples: components LDR 05, XD-80</li> </ul> </li> <li> <p>Proximity Sensors: Proximity sensors detect the presence or absence of nearby objects without physical contact. They are employed in smart appliances, touchless interfaces, and object detection applications.</p> <ul> <li>Example: Lidar-based smart vacuum cleaners, sonar, etc.</li> </ul> </li> <li> <p>Pressure Sensors: Pressure sensors measure force or pressure applied to a surface. They are used in smart home devices like smart mattresses for sleep monitoring, etc.</p> <ul> <li>Example: smart mattresses, etc. </li> </ul> </li> <li> <p>Gas and Air Quality Sensors: These sensors monitor the levels of various gases and pollutants in the air, including carbon dioxide, carbon monoxide, volatile organic compounds (VOCs), and particulate matter. They are essential for indoor air quality monitoring, pollution detection, and ventilation control.</p> <ul> <li>Example: Aqara TVOC https://www.aqara.com/us/product/tvoc-air-quality-monitor/</li> </ul> </li> <li> <p>Sound and Noise Sensors: Sound sensors capture audio signals and detect noise levels in the environment. They are utilized in smart home security systems, noise monitoring, and acoustic event detection.</p> <ul> <li>Example: any microphone or smart voice assistant (e.g. Amazon Echo Dot)</li> </ul> </li> <li> <p>Biometric Sensors: Biometric sensors measure unique biological traits such as fingerprints, facial features, or heart rate. They are used for user authentication, health monitoring, and personalized services</p> <ul> <li>Example: an smart medicine dispenser with user recognition</li> </ul> </li> <li> <p>Gesture Recognition Sensors: Gesture recognition sensors detect and interpret human gestures and movements. They enable intuitive user interfaces and gesture-based control in smart devices, interactive displays, and wearable technology. - Example: Leap Motion https://www.ultraleap.com/</p> </li> <li> <p>Occupancy and Presence Sensors: These sensors detect the presence of people within a space. They are used for occupancy sensing, crowd monitoring, and smart lighting control in buildings and public spaces.</p> <ul> <li>Example: Smart surveillance cameras, specialized occupancy sensors, etc.</li> </ul> </li> </ol>"},{"location":"IoT/#actuators","title":"Actuators","text":"<p>Actuators are devices that convert electrical signals or energy into physical actions or movements. In the context of IoT and Ambient Intelligence (AmI) environments, actuators enable systems to interact with and affect the physical world based on data inputs and decisions taken by the ML-enabled components.</p> <ol> <li> <p>Motorized Actuators: Motorized actuators convert electrical energy into mechanical motion. They are used in various IoT devices for controlling the movement of physical objects, such as opening and closing doors, windows, curtains, blinds, or adjusting the position of robotic arms and mechanisms.</p> <ul> <li>Common examples: garage door motors, automated blinds</li> </ul> </li> <li> <p>Solenoid Actuators: Solenoid actuators use electromagnetic force to produce linear motion. They are employed in IoT systems for tasks such as locking and unlocking doors, valves, or latches, as well as in automotive applications for controlling fluid flow and pneumatic systems.</p> <ul> <li>Common example: building's main door latch (e.g. activated from entryphone)</li> </ul> </li> <li> <p>Relays and Electromagnetic actuators: Relays are electromagnetic switches that control the flow of electricity between circuits. They are utilized in IoT devices for switching power on or off to connected electrical devices, such as lights, appliances, or heating systems. Similarly, electromagnetic actuators use electromagnetic force to produce linear or rotary motion. They are utilized in IoT systems in home automation or industrial control applications.</p> <ul> <li>Example: smart switches, smart plugs, fire door release mechanisms</li> </ul> </li> <li> <p>Servo Motors: Servo motors are rotary actuators that provide precise control over angular position, velocity, and acceleration. They are commonly used in robotics, drones, camera gimbals, and IoT devices requiring precise motion control.</p> <ul> <li>Examples: robotic arms, pan-tilt-zoom cameras, or automated surveillance systems.</li> </ul> </li> <li> <p>Pneumatic and Hydraulic Actuators: Pneumatic and hydraulic actuators use compressed air or fluid pressure to generate mechanical motion. They are employed in industrial IoT applications for tasks such as controlling valves, pumps, and robotic manipulators in manufacturing, process automation, and heavy machinery.</p> <ul> <li>Examples: Elevators, some mechanical beds</li> </ul> </li> <li> <p>Piezoelectric Actuators: Piezoelectric actuators generate mechanical motion in response to an applied voltage. They are used in IoT devices for precise positioning, vibration control, and haptic feedback in touchscreens, medical devices, and consumer electronics.</p> <ul> <li>Example: smart phones and tablets</li> </ul> </li> <li> <p>Shape Memory Alloys (SMAs): SMAs are materials that change shape in response to temperature changes or applied stress. They are used in IoT devices for shape memory actuators, such as smart valves, adaptive structures, and biomedical implants.</p> <ul> <li>Read more (optional): https://en.wikipedia.org/wiki/Shape-memory_alloy</li> </ul> </li> </ol>"},{"location":"IoT/#sensor-data-processing-and-analysis","title":"Sensor Data Processing and Analysis","text":"<p>Sensor data processing and analysis are essential components of IoT systems, enabling the extraction of knowledge from data, as well as actionable information from raw sensor data. In sensor data processing, collected data undergoes various stages of transformation, including filtering, aggregation, and normalization, to ensure its accuracy, reliability, and usability. Once processed, the data is then subjected to analysis techniques such as statistical analysis, machine learning, and data mining to uncover patterns, trends, and correlations. This analysis enables IoT systems to derive meaningful understanding, predict future outcomes, and make informed decisions in real-time. Sensor data processing and analysis has multiple applications, such as: anomaly detection, environmental monitoring, and personalized services.</p> <p>The following figure<sup>5</sup> shows how the process of training an ML model based off of historical (temporally-aggregated) IoT data:  </p> <p>Important</p> <p>Mandatory read: Understand the applications of DL in IoT (Sec. IV), as well as how IoT data can be aggregated and incorporated into different deep learning (DL) models (Sec. V).</p> <p>Mohammadi et al. 2018 \"Deep Learning for IoT Big Data and Streaming Analytics: A Survey\" https://doi.org/10.1109/COMST.2018.2844341</p> <p>Note</p> <p>Optional read: Alghanmi et al. 2021 \"Machine Learning Approaches for Anomaly Detection in IoT: An Overview and Future Research Directions\" https://doi.org/10.1007/s11277-021-08994-z</p>"},{"location":"IoT/#iot-areas-of-application","title":"IoT Areas of application","text":""},{"location":"IoT/#ioxt-internet-of-x-things","title":"IoXT: Internet of 'X' Things","text":"<p>Since the inception of the Internet of Things (original IoT), several other acronyms have appeared for specialized variants, to better explain certain fields of application of IoT technologies. Today we see a plethora of variants, such as:</p> <ul> <li>Internet of Robotics Things (IoRT)</li> <li>Consumer or Commercial Internet of Things (CIoT)</li> <li>Internet of Industrial Things (IIoT) or Industrial Internet of Things</li> <li>Internet of Military Things (IoMT)</li> <li>Internet of Educational Things (IoET) (e.g. https://doi.org/10.1016/j.iot.2022.100558 )</li> <li>etc.</li> </ul> <p>Note</p> <p>Optional read: \"Internet of Things: The Five Types of IoT\" https://syntegra.net/internet-of-things-the-five-types-of-iot/</p> <p>Optional read: \"The Role of IoT in Education\" https://www.arduino.cc/education/the-role-of-the-iot-in-education</p> <p>However, due to the nature of our course we will focus next on the Internet of Health(y) Things.</p>"},{"location":"IoT/#ioht-internet-of-healthy-things","title":"IoHT: Internet of Health(y) Things","text":"<p>We have already delved into the application of IoT devices as part of ambient intelligence (AmI) in the context of smart homes and their automation. Furthermore we have explored that the aims of this might be several: energy efficiency, increased comfort of its inhabitants, etc. However, as we have also emphasized, AmI 4 AHA and AAL are the fields in which ambient intelligence, and particularly IoT devices, can provide more societal benefits.</p> <p>As part of this AmI 4 AHA effort, the Internet of Health(y) Things (IoHT), or the Healthcare Internet of Things (H-IoT) emerges as a field in which the devices that are connected and interact with each other and cloud services are related to the provision of care and/or health condition management, or prevention.</p> <p>Of particular interest, in the field of AmI4AHA, or AAL, is the part of IoHT that considers the wearable technologies and IoT-based applications to support independent living of older adults, so that they can remain in their preferred environment longer.</p> <p>Important</p> <p>Mandatory reads:</p> <ul> <li>Baig et al. 2019 \"A Systematic Review of Wearable Sensors and IoT-Based Monitoring Applications for Older Adults\" https://doi.org/10.1007/s10916-019-1365-7</li> </ul> <p>Other IoHT solutions focus further in the applications within hospitals, or care facilities, as well as in-home e-health and tele-health provision.</p> <p>Note</p> <p>Optional reads:</p> <ul> <li> <p>Selvaraj et al. 2020 \"Challenges and opportunities in IoT healthcare systems: a systematic review\" https://doi.org/10.1007/s42452-019-1925-y</p> </li> <li> <p>Mishra et al. 2019 \"IoT Health care Monitoring and Tracking: A Survey\" https://doi.org/10.1109/ICOEI.2019.8862763</p> </li> <li> <p>Example application: Bassoli et al. 2017 \"An IoT approach for an AAL Wi-Fi-based Monitoring System\" https://doi.org/10.1109/TIM.2017.2753458</p> </li> </ul>"},{"location":"IoT/#intelligent-environments-beyond-the-house","title":"Intelligent Environments: beyond the house","text":"<p>Intelligent Workspaces leverage IoT technologies and advanced automation to enhance productivity, efficiency, and user experience within office environments. These environments integrate sensors, smart devices, and data analytics to optimize workspace layout, lighting, temperature, and resource allocation based on real-time usage patterns and employee preferences. For instance, think of a co-working space in which seats can be booked if not currently in use: sensors are needed to detect currently vacant seats, and a dynamic booking system to allow for seat booking in real time. Additionally, intelligent workspaces often incorporate smart meeting rooms, digital collaboration tools, and personalized workplace assistants to streamline communication, collaboration, and task management, fostering a more dynamic and adaptable work environment.</p> <p>Smart Building Management Systems. Smart buildings utilize IoT technologies to enhance operational efficiency, occupant comfort, and sustainability. They integrate interconnected sensors, actuators, and control systems to optimize energy usage, indoor air quality, and facility management. Smart buildings also enable predictive maintenance (for instance, smart lights informing the maintenance team of their end of life approaching), real-time monitoring, and adaptive control strategies to minimize costs, reduce environmental impact, and create more responsive and sustainable built environments.</p> <p>Energy Efficiency in Intelligent Environments. Energy efficiency in intelligent environments involves leveraging IoT technologies and data-driven approaches to optimize energy usage and reduce wastage. By integrating sensors, smart meters, and energy management systems, intelligent environments can monitor and analyse energy consumption patterns in real-time. This enables automated adjustments to lighting, heating, cooling, and other systems based on occupancy, environmental conditions, and energy demand.</p>"},{"location":"IoT/#data-security-and-privacy","title":"Data Security and Privacy","text":"<p>By definition, the IoT encompasses a vast network of interconnected physical objects globally, linked via the Internet. Envisioned to interconnect trillions of intelligent objects daily, these entities possess the capacity to gather, process, and communicate data regarding themselves and their surroundings. Prominent examples of IoT applications span various domains, including very sensitive information such as in healthcare, smart city infrastructure, surveillance systems, and data acquisition in public and defence sectors.</p> <p>Recent technological advancements have yielded smart sensor nodes and RFIDs, leading to a large number of wireless networks filled with intelligent devices continuously transmitting data to the Internet. Securing and preserving the privacy of this data within the IoT framework poses an enormous challenge, that needs to be given priority for present and future applications.</p> <p>Devices such as smart phone, WSNs and RFIDs etc., are the major components of IoT network which are basically resource constrained devices. Consequently, the design and implementation of security and privacy management schemes demand consideration of factors like performance optimization, minimal power consumption, resilience against attacks, data tampering prevention, and end-to-end security assurance. Security measures within IoT frameworks safeguard against unauthorized access, data alterations, or destruction, while privacy protocols aim to uphold individuals' rights to control the usage and purpose of collected information.</p> <p>Note</p> <p>Optional (but highly recommended) reads: - Chanal et al. 2020 \"Security and Privacy in IoT: A Survey\" https://doi.org/10.1109/JIOT.2019.2898113 - \"Cryptography Key Management, Authentication and Authorization for IoT\" - https://medium.com/@preetirajesh400/cryptography-key-management-authentication-and-authorization-for-iot-4198dfa0481b</p> <p>Note</p> <p>News on Bluetooth vulnerabilities (optional read): https://www.kaspersky.com/blog/bluetooth-vulnerability-android-ios-macos-linux/50038/ Examples of vulnerabilities: https://www.keyfactor.com/education-center/iot-device-security/</p>"},{"location":"IoT/#ethical-and-social-implications","title":"Ethical and Social Implications","text":"<p>The proliferation of IoT technology brings forth a series ethical and social implications that require careful consideration. Privacy concerns arise as IoT devices continuously collect, transmit, and analyze personal data, raising questions about consent, data ownership, and surveillance.</p> <p>Security vulnerabilities in IoT systems pose risks of unauthorized access, data breaches, and manipulation, threatening individuals' safety and privacy. Moreover, the deployment of IoT technologies in critical infrastructure, such as healthcare and transportation, raises concerns about reliability, accountability, and potential consequences of system failures.</p> <p>Additionally, the digital divide exacerbates societal inequalities, as access to and benefits from IoT technologies may not be equally distributed across populations. Ethical dilemmas emerge regarding the ethical use of AI algorithms in decision-making processes, potential biases, and unintended consequences.</p> <p>Example -- Barriers for adoption in IoHT: On of the main challenges faced by technologies such as the ones presented today (IoT, but particularly IoHT), is that of user acceptability. The following figure<sup>6</sup> shows the four biggest barriers:</p> <ol> <li>Having to wear a device that can be stigmatizing (i.e. shows weakness or lack of independence) is often a barrier for adoption.</li> <li>Data collection and processing itself might be perceived oftentimes as a threat that hinders acceptability.</li> <li>Constant alerts and warnings can be seen as an annoyance by end users, or perceived as patronizing, and have to be well-timed for assistance when required only.</li> <li>Finally, acceptability is dicreased by poor usability of the system (i.e. design that is not well-thought or that didn't involve the end users' needs).</li> </ol> <p></p>"},{"location":"IoT/#conclusion-and-recap","title":"Conclusion and Recap","text":"<p>In this lesson, we have presented the possibilities that the Internet of Things (IoT) concept opens for us. We have seen how, contrary to the concept of ambient intelligence, that focuses on the deployment of sensors into the environment and the prediction of user needs, the concept of IoT is closer to the hardware, as it is the network of connected things that can be any everyday object that is network-capable thanks to the emergence of cost-reduced integrated circuits that implement a full network stack. Alternatively a hub or gateway that can connect to the Internet provides access for a network of devices that transmit via a restricted bandwidth network infrastructure (such as Zigbee, Z-Wave, etc).</p> <p>We have also explored the IoT ecosystem and its components: edge and cloud computing,  and machine learning (ML/AI). We have also briefly introduced the protocols and standards that exist in the IoT field.</p> <p>Additionally, we have introduced the most common types of sensors and actuators, with some examples. Moreover, we have delved into the processing of data by machine learning techniques, particularly deep learning methodologies.</p> <p>To finalize, we have covered the data security, privacy, as well as social and ethical questions raised by IoT usage and spread.</p>"},{"location":"IoT/#references","title":"References:","text":"<p>Warning</p> <p>References have been included along the text, please review the material and find tip boxes marked as Important, which contain mandatory reading material.</p> <p>As explained in the previous chapter, a test will be conducted including topics covered in this material.</p>"},{"location":"IoT/#moodle-test","title":"Moodle test","text":"<ul> <li>The moodle test will be developed during practice sessions on Wednesday, 16 April 2025 at 4.30pm CEST, jointly to the module on Intelligent Environments.</li> <li>The questions will be based on this webpage and all the mandatory readings proposed. </li> </ul> <ol> <li> <p>Image from: Medriva \u21a9</p> </li> <li> <p>Images from http://dx.doi.org/10.3390/s21103549 \u21a9\u21a9</p> </li> <li> <p>security, in English refers to the security against burglars and/or damage, etc. (i.e. security of property)\u00a0\u21a9</p> </li> <li> <p>safety in English refers to the well-being of humans (i.e. against injuries or death)\u00a0\u21a9</p> </li> <li> <p>Image from: LinkedIn \u21a9</p> </li> <li> <p>Figure from: https://doi.org/10.1007/s10916-019-1365-7 \u21a9</p> </li> </ol>"},{"location":"multimodal_interaction/","title":"Multimodal interaction, datasets, and synthetic generation","text":"<p>Manuel Benavent Lled\u00f3, David Ortiz P\u00e9rez, and Jose Garc\u00eda Rodr\u00edguez</p>"},{"location":"multimodal_interaction/#introduction","title":"Introduction","text":"<p>Definition</p> <p>Modality refers to a certain type of information and/or representation format in which information is stored. There is a wide range of modalities: some raw modalities closer to sensor data such as speech signals and images, that can be expressed as language or detected objects, or going one step further, sentiment intensity or object categories.</p> <p>Why do we need to explore multimodal data?</p> <ul> <li>From human perspective, we naturally interact with the world through multiple modalities, such as vision, language, and touch. Therefore, building systems that can understand and generate multimodal data enables more natural and intuitive human-computer interaction.</li> <li>From AI perspective, the information is present in different modalities and therefore it will often show diverse qualities, structures and representations. A comprehensive understanding of the different modalities will provide complementary information about a phenomenon. For example, in understanding a scene, combining visual data with textual descriptions can provide a more comprehensive understanding than using either modality alone.</li> <li>As a result, leveraging multiple modalities often leads to improved performance in various domains due to the richer representations of the data that enhance the robustness to noise and variability of the models. In this way, the lack of data from a modality (let's say an occlusion in a video) may be compensated with a different one (e.g., audio recordings). Moreover, multimodal data facilitates cross-modal learning, where knowledge from one modality can be transferred to another, enabling better generalization.</li> </ul>"},{"location":"multimodal_interaction/#core-challenges-in-multimodal-interaction","title":"Core Challenges in Multimodal Interaction","text":"<p>Multimodal systems present a series of technical challenges that are understudied in conventional machine learning. This section covers the basic concepts, you may check bibliography for additional information in this area.</p> <p>(Optional) MultiModal Machine Learning Course from Carnegie Mellon University</p>"},{"location":"multimodal_interaction/#representation","title":"Representation","text":"<ul> <li>Definition: Learning representations that reflect cross-modal interactions between individual elements, across different modalities.   This is a core building block for most multimodal modeling problems. Individually, each modality can be seen as a \u201clocal\u201d representation or a representation using holisitic features.</li> <li>Sub-challenges</li> </ul>"},{"location":"multimodal_interaction/#alignment","title":"Alignment","text":"<ul> <li>Definition: Identifying and modeling cross-modal connections between all elements of multiple modalities, building from the data structure.   Most modalities have internal structure with multiple elements:</li> </ul> <p> - Sub-challenges:</p> <p></p>"},{"location":"multimodal_interaction/#reasoning","title":"Reasoning","text":"<ul> <li>Definition: Combining knowledge, usually through multiple inferential steps, exploiting multimodal alignment and problem structure.   For example, LLMs are a great source of external knowledge for multimodal reasoning.</li> <li>Sub-challenges:</li> </ul>"},{"location":"multimodal_interaction/#generation","title":"Generation","text":"<ul> <li>Definition: Learning a generative process to produce raw modalities that reflects cross-modal interactions, structure and coherence.</li> <li>Sub-challenges:</li> </ul>"},{"location":"multimodal_interaction/#transference","title":"Transference","text":"<ul> <li>Definition: Transfer knowledge between modalities, usually to help the target modality which may be noisy or with limited resources.</li> </ul> <p> - Sub-challenges:</p> <p></p>"},{"location":"multimodal_interaction/#quantification","title":"Quantification","text":"<ul> <li>Definition: Empirical and theoretical study to better understand heterogeneity, cross-modal interactions and the multimodal learning process.</li> <li>Sub-challenges:</li> </ul>"},{"location":"multimodal_interaction/#real-world-challenges","title":"Real-World Challenges","text":"<p>Besides the technical challenges, in the real world multimodal systems have to face additional challenges.</p> <ul> <li>Robustness: to overcome noisy or missing data in some modalities.</li> <li>Trustworthy: people who use the system must trust it. It is preferable to have a system that does not provide an output (abstains) rather than making unclear predictions on noisy data or missing data.</li> <li>Variability: despite a dataset may be captured with high variability of subjects and locations, there are always unseen events that must be handled.</li> <li>Fairness: biases must be quantified and addressed to make the systems fair.</li> <li>Privacy: it is a crucial aspect when capturing data.</li> </ul>"},{"location":"multimodal_interaction/#examples-and-applications-of-multimodality","title":"Examples and Applications of Multimodality","text":""},{"location":"multimodal_interaction/#multimodal-architectures","title":"Multimodal architectures","text":""},{"location":"multimodal_interaction/#how-to-fuse-data-from-different-modalities","title":"How to fuse data from different modalities?","text":"<p>(Optional) Multimodal Learning with Transformers: A Survey. Peng Xu, Xiatian Zhu, David A. Clifton https://doi.org/10.48550/arXiv.2206.06488</p> <p>There are many ways of combining modalities but we can mainly categorize them in early, late or intermediate fusion strategies.</p> <ul> <li>Early fusion relies on the combination of modalities since the beginning, after the combination, the data is processed by the model. This method enables learning modality dependencies since the beginning. (See a and b in the figure.)</li> <li>Late fusion relies on the combination of modalities after being processed by individual models. With this processing of the data, we obtain modality features, which are combined for a multimodal result. This method enables the process of each modality independently, as each modality has different challenges. (See c in the figure.)</li> <li>Intermediate fusion relies in the combination of modalities while being processed by the models. This method enables learning dependencies since the beginning as well as facing modality challenges kind of individually. Examples are cross-attention strategies. (See e and f in the figure.)</li> </ul> <p>In order to make the combinations of data modalities several options are available for combination, including concatenating the data, computing a sum, generating a weighted sum using static weights, weighting by a model parameter that may vary, or computing a product.</p> <p></p>"},{"location":"multimodal_interaction/#clip","title":"CLIP","text":"<p>(Optional) Learning Transferable Visual Models From Natural Language Supervision. Alec Radford, Jong Wook Kim et al. https://doi.org/10.48550/arXiv.2103.00020</p> <p>Use of contrastive learning to align visual and textual modalities. The primary advantage of this model is that it provides a pre-trained representation of the data using both images and text. This pre-existing knowledge is particularly useful in zero-shot learning scenarios for downstream tasks.</p> <p></p> <p></p>"},{"location":"multimodal_interaction/#nerf-and-gaussian-splatting","title":"NeRF and Gaussian Splatting","text":"<p>(Optional) NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis. Mildenhall, B., Srinivasan, P. P., Tancik, M., Barron, J. T., Ramamoorthi, R., &amp; Ng, R. https://doi.org/10.48550/arXiv.2003.08934</p> <p>(Optional) 3D Gaussian Splatting for Real-Time Radiance Field Rendering. Kerbl, B., Kopanas, G., Leimk\u00fchler, T., &amp; Drettakis, G. https://doi.org/10.48550/arXiv.2308.04079</p> <p>Neural Radiance Fields (NeRF) and Gaussian Splatting stand out as two prominent techniques in 3D scene reconstruction. NeRF captures radiance fields from multiple viewpoints to produce photorealistic scenes. Although proficient at generating high-quality images, NeRF's computational demands render it less ideal for real-time applications, such as those needed for game engines like Unreal Engine, commonly used for synthetic data generation.</p> <p></p> <p>The Gaussial Splatting model initiates with camera calibration using Structure-from-Motion (SfM) alongside a sparse point cloud. At rendering time, a process called Gaussian rasterization transforms each Gaussian particle into the appropriate red, blue and green colored pixels that make up each view.</p> <p></p> <p>This approach yields remarkable results with minimal input. Unlike methods that necessitate Multi-View Stereo (MVS) data, Gaussian Splatting employs an optimization procedure to generate a concise and accurate representation of the scene. Gaussian Splatting excels in producing smooth and continuous visualizations, making it suitable for applications where aesthetics and clarity are crucial. The training time for Gaussian splatting is approximately 50 times faster than NeRFs for the same or better quality.</p> <p>Groundtruth vs Gaussian Splatting:</p> <p></p>"},{"location":"multimodal_interaction/#dalle-2","title":"DALLE-2","text":"<p>(Optional) Hierarchical Text-Conditional Image Generation with CLIP Latents. Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, Mark Chen https://doi.org/10.48550/arXiv.2204.06125</p> <p>One of the state of the art models in text to image generation. This model uses a pretrained CLIP, we learn a joint representation space for text and images. A CLIP text embedding is fed into the diffusion prior model to generate an image embedding, and the using a diffusion decoder obtaining the final image. Explicitly generating the image embeddings using the diffusion prior improves the diversity of the data, but keeps the semantics and style, with a minimal loss.</p> <p></p> <p>(Optional) Diversify Your Vision Datasets with Automatic Diffusion-Based Augmentation Dunlap, L., Umino, A., Zhang, H., Yang, J., Gonzalez, J. E., &amp; Darrell, T. https://doi.org/10.48550/arXiv.2305.16289</p> <p>Link to an example of data augmentation using diffusion models. https://colab.research.google.com/drive/1wRW7yDLsCYC6JjcAzCFgOaHHJcLhCiEo?usp=sharing</p>"},{"location":"multimodal_interaction/#whisper","title":"Whisper","text":"<p>(Optional) Robust Speech Recognition via Large-Scale Weak Supervision. Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever https://doi.org/10.48550/arXiv.2212.04356</p> <p>Whisper is the state of the art model in transcribing audio, obtaining the text that has been said on the audio. This model obtains a log mel-spectogram from the audio and uses convolutional neural networks to obtain the audio representation to feed a transformer. With this audio representation, the transformer decodes the text, and adds timestamps depending on which part of the audio is being processed. Whisper outperforms the rest of models, obtaining similar results as professional transcribers.</p> <p></p> <p></p>"},{"location":"multimodal_interaction/#multimodal-datasets","title":"Multimodal datasets","text":"<p>Data is crucial for deep learning and therefore multimodal datasets have been developed for different purposes. Some examples:</p> <p>(Optional) ActionSense: A Multimodal Dataset and Recording Framework for Human Activities Using Wearable Sensors in a Kitchen Environment. Joseph DelPreto et al. https://action-sense.csail.mit.edu/</p> <p>(Optional) Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph.  Amir Zadeh et al. https://doi.org/10.18653/v1/P18-1208</p> <p>(Optional) IEMOCAP: interactive emotional dyadic motion capture database. Carlos Busso et al. https://doi.org/10.1007/s10579-008-9076-6</p> <p>(Optional) Social-IQ: A Question Answering Benchmark for Artificial Social Intelligence Amir Zadeh et al. https://doi.org/10.1109/CVPR.2019.00901</p> <ul> <li>Overview of ActionSense sensors:</li> </ul> <p></p>"},{"location":"multimodal_interaction/#references","title":"References:","text":"<p>Warning</p> <p>References have been included along the text, please review the material and find tip boxes marked as Important, which contain mandatory reading material.</p> <p>As explained in the previous chapter, a test will be conducted including topics covered in this material.</p>"},{"location":"multimodal_interaction/#moodle-test","title":"Moodle test","text":"<ul> <li>The moodle test will be developed during practice session on Wednesday 7 May at 6pm CET.</li> <li>The test has a maximum duration of 30 minutes from the start.</li> <li>The test consists of 20 triple choice questions.</li> <li>Each wrong answer subtracts 1/3 of the value of a correct answer.</li> <li>The mark for the test will be considered as one of the marks for the theoretical part of the course. See the overall evaluation of the course in the general conditions.</li> <li>The questions will be based on this webpage and all the mandatory readings proposed.</li> </ul>"},{"location":"responses_psymo_en/","title":"1. Example Based on the PsyMo Dataset","text":"<p>Example Context - Trait: Self-Esteem (Rosenberg Self-Esteem), with 3 ordinal classes: Low, Normal, and High. - Subject: ID 260 (part of the evaluation set, IDs 251\u2013312). - Runs considered: 7 walks (one per variation, from a single camera angle) for simplicity. - Variations:   - <code>bg</code> \u2192 Carry Bag   - <code>cl</code> \u2192 Clothing Change   - <code>nm</code> \u2192 Normal Walking   - <code>ph</code> \u2192 Talking on Phone   - <code>txt</code> \u2192 Texting   - <code>wsf</code> \u2192 Walk Speed Fast   - <code>wss</code> \u2192 Walk Speed Slow </p>"},{"location":"responses_psymo_en/#1-run-level-evaluation","title":"1. Run-Level Evaluation","text":"<p>Each of the 7 sequences is evaluated independently:</p> Run True Label Model Prediction 1 High High 2 Normal Normal 3 High High 4 High High 5 Low Normal 6 High High 7 Low Low <ul> <li>True Positives (TP) for the High class: 4  </li> <li>False Positives (FP) for High: 0  </li> <li>False Negatives (FN) for High: 0  </li> <li>True Negatives (TN) for High: 2  </li> </ul> <p>Hence: </p> <p>And the overall run-level accuracy (7 runs, 6 correct):</p> <p> </p>"},{"location":"responses_psymo_en/#2-subject-level-evaluation","title":"2. Subject-Level Evaluation","text":"<p>The 7 predictions are aggregated and a single label is assigned by majority vote:</p> Prediction Count High Normal Low Times 4 2 1 <ul> <li>The majority class is High \u2192 final label for the subject.  </li> <li>Compared to the subject\u2019s true label (High) \u2192 correct.</li> </ul>"},{"location":"responses_psymo_en/#2-meaning-of-the-label-000_00_0_0_bg","title":"2. Meaning of the Label <code>000_00_0_0_bg</code>","text":"<p>The label follows the scheme: SubjectID_SequenceIndex_CameraView_RunIndex_Variation:</p> <ol> <li><code>000</code> \u2192 Subject ID </li> <li><code>00</code> \u2192 Sequence index (first sequence).  </li> <li><code>0</code> \u2192 Camera viewpoint (0\u00b0 frontal).  </li> <li><code>0</code> \u2192 Run (repetition) index (first pass).  </li> <li><code>bg</code> \u2192 Variation code (\u201ccarry bag\u201d).</li> </ol> <p>Altogether, <code>000_00_0_0_bg</code> is the file for the first sequence recorded with the front-facing camera (0\u00b0) on the first pass for subject 0, performing the \u201ccarry bag\u201d variation.  </p>"}]}